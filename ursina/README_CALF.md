# CALF Training with Ursina Visualization

Полноценная реализация CALF (Critic as Lyapunov Function) агента с 3D визуализацией в реальном времени.

## Что такое CALF?

CALF - это подход к безопасному обучению с подкреплением, где:
- **Критик используется как функция Ляпунова** для гарантии достижения цели
- **Номинальная безопасная политика π₀** (PD-контроллер) включается, когда критик не может сертифицировать действие актора
- **Relax probability P_relax** экспоненциально убывает, позволяя больше exploration в начале и больше safety к концу

## Режимы работы CALF

Траектории агентов окрашены в разные цвета в зависимости от режима:

- **Синий (TD3)**: Действие актора **сертифицировано** (Ляпунов-условие выполнено)
- **Зелёный (Relax)**: Действие актора **не сертифицировано**, но разрешено из-за relax (исследование)
- **Оранжевый (Fallback)**: Включена номинальная безопасная политика π₀ (PD-контроллер)

## Запуск

```bash
cd ursina
python train_calf_visual.py
```

## Параметры CALF

В `train_calf_visual.py`:

```python
LAMBDA_RELAX = 0.9999    # Relaxation factor (выше = больше exploration)
NU_BAR = 0.01            # Lyapunov decrease threshold
KAPPA_LOW_COEF = 0.5     # Lower K_∞ coefficient
KAPPA_UP_COEF = 2.0      # Upper K_∞ coefficient
```

**Lambda_relax**: Чем ближе к 1, тем дольше агент исследует (relax). Рекомендуется 0.999-0.9999.

## Визуализация

- **25 агентов** одновременно обучаются и показывают траектории
- **Critic heatmap**: Q-values как 3D поверхность (синий=низкий, красный=высокий)
- **Grid overlay**: Сетка на поверхности критика
- **Mode switching**: Цвета траекторий показывают переключения режимов CALF

## Статистика на экране

```
=== CALF Statistics ===
P_relax: 0.99990000      # Текущая relax probability
Certification: 0.850     # Доля сертифицированных действий
Intervention: 0.120      # Доля использования π₀ (fallback)
Relax: 0.030             # Доля relax событий
```

## Управление

- **P** - Pause/Resume обучение
- **Q** - Quit
- **WASD** - Двигать камеру
- **Scroll** - Zoom

## Сохранение моделей

Модели автоматически сохраняются:
- Каждые 50 эпизодов: `checkpoints/calf_episode_X.pth`
- После завершения: `trained_calf_final.pth`

## Сравнение с TD3

Для сравнения можно запустить чистый TD3:
```bash
python train_td3_visual.py
```

**Различия**:
- TD3: траектории только синие (один режим)
- CALF: траектории меняют цвет (три режима: td3/relax/fallback)

## Теоретическая база

См. [RL/CALF.md](../RL/CALF.md) для полного описания алгоритма CALF по диссертации Osinenko 2024.

**Ключевая идея**: CALF гарантирует достижение цели (goal-reaching property), при этом позволяя агенту обучаться и исследовать благодаря механизму relax probability.
